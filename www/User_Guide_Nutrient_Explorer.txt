User Guide for Nutrient Explorer R Shiny App

Purpose: An analytical framework (downloadable R Shiny application) to visualize and investigate drivers of surface water quality.

Features
     - This application provides the user with the ability to analyze lake total nitrogen or total phosphorus data for Northeastern U.S. lakes based on LAGOS NE data (https://lagoslakes.org/lagos-ne/).
     - Alternatively, the user can upload and analyze their own surface water (lake, stream, river) dataset after properly formatting the data (see below). 
     - The user can summarize and visualize temporal and spatial patterns using a variety of approaches.
     - Subsets of the dataset can be created for further analysis using various characteristics of the variables, such as date, location, etc. 
     - Finally, the user can apply either random forest modeling or multiple linear regression to assess which predictor variables best model the spatial patterns in the water quality dataset and the models can be used to predict water quality concentrations for watersheds or locations lacking data. 

Opening the Application:
     1. Download and unzip the Zip File containing the app and associated files.
     2. Open RStudio > Click on “Project” (blue box, upper right) > Select “Open Project.”
     3. Navigate to the file folder where you saved the Application.
     4. Click on the “Nutrient_Explorer.Rproj” file and select Open.
     5. On bottom right panel of RStudio, under the Files Tab, click on “ui.R” to open this R code file.
     6. On bottom right panel of RStudio, under the Files Tab, click on “server.R” to open this R code file.
     7. Check to make sure you have all the necessary packages installed before the next step.
     8. Near the Upper Right, click on the “Run App” button with the green arrow pointing to the right.  This will open the User Interface for the application in a separate window.

Step-by-Step Instructions for Using this Application:
     1. “Load Data” Tab:
       a. In the “Load Data” tab, for “Dataset Options” select either LAGOS test or LAGOS or "Upload new dataset" 	by clicking the browse button.   
       b. Click “Load this dataset” (if uploading new dataset, wait until it says "Upload complete" before 	clicking this button
       c. Try changing the different “Endpoint options” and “Color palette” options. 
       d. Click on the “Summary Table” button on the bottom. Try changing the “Variable group” option - you will 	need to click the "Summary table" button again to update the table with a new variable group option.  
     2. “Explore Data” Tab:
       a. Check out the different sub-tabs: “Summary Info,” “Time Series,” etc.
       b. “Summary Info” tab: Select from the different “Endpoint options”
       c. “Time Series” tab: 
         i. Toggle between the different endpoints. 
         ii. Test out the interactive capabilities of the plots (e.g., zooming in or switching on and off 	different datasets).
       d. “Endpoint HUC2 Summaries” tab: explore the different plot options
       e. “Predictor Variables HUC2 Summaries” tab: try selecting different predictor variables and Adjusting 
	the Y axis scale. 
       f. “Correlations” Tab: 
         i. “Bivariate” tab: select different variables, then click “Display Plots”
         ii. “Multivariate” tab: select an endpoint variable and up to 5 predictor variables, 
	then click “Display plots.”
       g. “Maps” tab: select an “endpoint option” from the top
       h. “Misc” tab: select between the different “endpoint options” at the top
     3. “Create a Subset” tab: 
       a. Adjust the different dataset ranges variables such as the Year, Month, IWS (watershed area, ha), 	Elevation, lake area, lake depth, Total Nitrogen, Total Phosphorus, etc.
       b. Subset the data by selecting specific Program Names, Program Types or HUC2 zones.
       c. Click “Save my subset.”
     4. “Explore Subset” Tab:
       a. Follow the same steps as step 2 above. 
     5. “Run Models” Tab: 
       a. Select the “Random Forest” model option first and click “Choose this Model”
         i. Select the endpoint for the model run (LogTP was used for this paper). 
         ii. Mouse over the different Model parameter options such as “ntree” to learn about each. 
         iii. Select predictor variables for the model (center section of the app).
            1. Practice using the different ways of selecting variables, such as by clicking “Select all default 	variables.” Or by clicking “Select all in Group*”, or by clicking in the blank box for each variable group 	and choosing a variable from the dropdown. 
            2. Practice removing variables by either clicking on the “X” on the right-hand side of the variable 	name or by clicking on the variable to highlight it in blue and then pressing the backspace or delete 	button on your keyboard.  
            3. Notice the pop-up information when mousing over a variable to get more detailed information 
	about the variable. 
            4. Once all variables are chosen, click “Run random forest” button on the bottom left. 
            5. Scroll down to see the initial results and figures that appear for the model
            6. Click on the “See additional plots and maps” button on the bottom right
            7. Select a variable option from the drop down and click “Display partial dependence plot”
            8. If using default dataset: 
		a. Click “Show prediction map for whole region (if using deafult dataset only!!!).” 
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		b. Try adjusting the prediction map color legend with the slider. 
		c. Click "Download prediction results to csv (Default Dataset)"
		d. Click “Save prediction map (Default Dataset)”
		e. Change the "Endpoint concentration criterial value"
		f. Click "Show prediction map in bicolor (Default Dataset)"
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		g. Click "Save prediction map in bicolor (Default Dataset)"
	    9. If using New Dataset:
		a. Click "Browse..." button under "Load new dataset (if have new variables button)"
		b. Click “Show prediction map for whole region (if using new dataset only!!!).”
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		c. Try adjusting the prediction map color legend with the slider.  
		d. Click "Download prediction results to csv (New Dataset)"
		e. Click “Save prediction map (New Dataset)”
		f. Change the "Endpoint concentration criterial value"
		g. Click "Show prediction map in bicolor (New User Dataset)"
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		h. Click "Save prediction map in bicolor (New User Dataset)"
       
	b. Select the “Linear regression” model option and click “Choose this Model”
         i. Select the endpoint for the model run (LogTP was used for this paper). 
         ii. Select predictor variables for the model (center section of the app).
            1. Either manually select variables, as described for the random forest model above, or click 
	“Link variables from random forest” button at the top (and choose the number of variables to select). 
         iii. Step 1 Run Correlation Analysis
            1. Select correlation criteria (variables with correlation value above 0.9 will be flagged). 
            2. Click “Run Correlation Analysis”
               a. Scroll down and click on “only show cells with high correlation”
                  i. Based on the correlated variables (those displayed in red, with black background), 
	manually choose one of the correlated variables and delete it from the above predictor 
	variable selection area. 
               b. Click “Run Correlation Analysis” and repeat above until no correlated variables remain. 
         iv. Step 2 Run Subset Selection
            1. Click “Run Subset Selection” button.
            2. Scroll down and follow the instructions in red, which describe how to select the best of 
	the five models. 
         v. Step 3 Finalize Regression Model:
            1. Scroll back up and select “Finalize Regression Model”
            2. Scroll down and look at the table and check if any VIF values are flagged.  
		If so, remove that variable and reselect “Finalize Regression Model”
         vi. Step 4 Make Model Predictions: 
            1. If using default dataset: 
		a. Click “Show LR prediction map for whole region (if using deafult dataset only!!!)” 
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		b. Try adjusting the prediction map color legend with the slider
		c. Click "Download LR prediction results to csv (Default Dataset)"
		d. Click “Save LR prediction map (Default Dataset)”
		e. Change the "Endpoint concentration criterial value"
		f. Click "Show prediction map in bicolor (Default Dataset)"
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		g. Click "Save prediction map in bicolor (Default Dataset)"
	    2. If using New Dataset:
		a. Click "Browse..." button under "Load new dataset (if have new variables button)"
		b. Click “Show LR prediction map for whole region (if using new dataset only!!!).”
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		c. Try adjusting the prediction map color legend with the slider.   
		d. Click "Download LR prediction results to csv (New Dataset)"
		e. Click “Save prediction map (New Dataset)”
		f. Change the "Endpoint concentration criterial value"
		g. Click "Show prediction map in bicolor (New Data)"
		(It takes a few seconds for the map to display - may need to scroll down to see it.) 
		h. Click "Save prediction map in bicolor (New Data)"

Instructions for formatting new dataset (for data exploration and training models):
     1. Download example data file from the Load Data Tab to see how the datasets need to be formated in general.

     2. The new dataset needs to have the exact same header/column names for the first 24 columns: 
	Name, LAGOS_Lake_ID, HU8ZoneID, HU8, programname, programtype, Lat, Long, HU2, Year, Month, 
	Day, Date, Elevation, MaxDepth, MeanDepth, lake_area_ha, iws_ha, iws_slope_mean, 
	TN, LogTN, TP, LogTP.
	a. Note that for column names like "LAGOS_Lake_ID," you can just use your own site IDs, but the header 
	has to be called "LAGOS_Lake_ID."  The same rule applies to these other required header names. For 	example, for "iws_ha" you can put in watershed area of site area. 
	b. The HU8 column is necessary for making predictions, but the data you provide could be at a different 	scale (e.g., HUC12 or other watershed level), but the column name will have to remain as "HU8." 	Alternatively, in the this new training dataset, the HU8 column can have just 99999 for all values 
	and the model section can still work as long as the dataset used for predictions (described below) 
	has true watershed IDs.
	c. Both the Year and Month columns are needed in order for the one of the Time Series plots. 
	d. The first 7 columns can be given 99999 as the values and the app will still work, 
	though certain freatues will not work. 
	e. IWS variables can replaced by watershed area, etc. variables. 

     3. If you are missing one of these required variables, it is best to replace with 99999 and not NA, 
	as the NA will cause the removal of all rows during a step to remove all NAs.   Again, you cannot 
	delete these columns and column names from your dataset.  They must be present for the application 
	to work.   

     4. For the user provided predictor/explanatory variables, such as land use, weather, deposition, make 
	sure these variables have certain key words in them (so that the application can recognize them):
	a. For NLCD land use: "nlcd" or "NLCD" or "landuse" or "LANDUSE"
	b. For Nitrogen input variables: "N_" or "n_" or "TN_" or "tn_"
	c. For Phosphorus input variables: "P_" or "p_" or "TP_" or "tp_"
	d. For Aerosol related variables: "Aerosol" or "aerosol" or "AOD"
	e. For Weather variables: "Tmax" or "Tmin" or "Tmean" or "Precip" or "LST" or "FIRE" or "SNOW"
	f. For deposition: "Atmo" or "Ndep" or "Pdep" or "Sdep" or "Dep_"
	g. For vegetation variables: "Vegetation" or "NPP" or "canopy" or "Canopy"
	h. For Surface water, Watershed, & Misc.: "slope", "Slope", "iws", "IWS",
	"shed","lake_area_ha","stream_length","depth","Depth","stream_order","stream_width","Elevation",
	"Month" (of sampling),"Year" (of sampling).

Instructions for formatting new prediction dataset 
	(for modeling section, when applying trained model to make predictions for a specific region):
     1. The above formating rules apply here as well.
     2. Make sure this dataset has the same predictor variables (with same column names) 
	as those in the trained model.
     2. The HU8 column is necessary for making predictions, but the data you provide could be at a different 	scale (e.g., HUC12 or other watershed level), but the column name will have to remain as "HU8."
  
Note: if switching between the default and a new user dataset, it is best to close and re-open the app, to clear out the system memory.  

For questions or comments contact: Michael Pennino at pennino.michael@epa.gov